{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the outputs env\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "shutil.rmtree('saved_models', ignore_errors=True)\n",
    "shutil.rmtree('saved_params', ignore_errors=True)\n",
    "shutil.rmtree('saved_results', ignore_errors=True)\n",
    "\n",
    "os.mkdir('saved_models/')\n",
    "os.mkdir('saved_params/')\n",
    "os.mkdir('saved_results/')\n",
    "\n",
    "shutil.rmtree('outputs', ignore_errors=True)\n",
    "os.mkdir('outputs/')\n",
    "os.mkdir('outputs/yeast/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw figures for NeurSC results\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def get_prediction_statistics(errors: list):\n",
    "\tlower, upper = np.quantile(errors, 0.25), np.quantile(errors, 0.75)\n",
    "\tprint(\"<\" * 80, flush=True)\n",
    "\tprint(\"Predict Result Profile of {} Queries:\".format(len(errors)), flush=True)\n",
    "\tprint(\"Min/Max: {:.4f} / {:.4f}\".format(np.min(errors), np.max(errors)), flush=True)\n",
    "\tprint(\"Mean: {:.4f}\".format(np.mean(errors)), flush=True)\n",
    "\tprint(\"Median: {:.4f}\".format(np.median(errors)), flush=True)\n",
    "\tprint(\"25%/75% Quantiles: {:.4f} / {:.4f}\".format(lower, upper), flush=True)\n",
    "\tprint(\">\" * 80, flush=True)\n",
    "\terror_median = abs(upper - lower)\n",
    "\treturn error_median\n",
    "\n",
    "def interperting_results(file_names, test_data, params_data, fontsize=12):\n",
    "    test_data['q-error'] = test_data['q-error'] * math.log2(10)\n",
    "    for file_name in file_names:\n",
    "        q_errors = test_data[test_data['File Name'] == file_name]['q-error'].to_numpy()\n",
    "        # params = params_data[params_data['File Name'] == file_name]\n",
    "        # total_square_loss = np.sum(np.square(q_errors))\n",
    "        # total_l1_loss = np.sum(np.abs(q_errors))\n",
    "        # print('lr: {}, epochs: {}'.format(params['Learning Rate'].to_numpy()[0], params['Epochs'].to_numpy()[0]))\n",
    "        # print(\"Evaluation result of Eval dataset(log2 based): Total Loss= {:.4f}, Total L1 Loss= {:.4f}\".format(total_square_loss, total_l1_loss))\n",
    "        # get_prediction_statistics(q_errors)\n",
    "        # print()\n",
    "\n",
    "    test_data['q-error'] = test_data['q-error'] ** 2\n",
    "    test_data = test_data.groupby('File Name', as_index=False).aggregate({'q-error':'sum'})\n",
    "    test_data['File Name'] = test_data['File Name'].replace('_', '\\n', regex=True)\n",
    "    sns.barplot(test_data, x='File Name', y='q-error')\n",
    "    plt.xlabel('File Name', fontsize=fontsize)\n",
    "    plt.ylabel('Total Squared log10(q-error)', fontsize=fontsize)\n",
    "    # plt.ylim(0, 9000)\n",
    "    plt.show()\n",
    "\n",
    "def read_test_file(file_name, test_dir, test_name, pure=False):\n",
    "    # test_data = [['Epochs', 'Query Size', 'Query Type', 'Pred', 'Card', 'q-error'], [...], ...]\n",
    "    name_tokens = test_name.split('_')\n",
    "    epochs = int(name_tokens[4])\n",
    "    res = []\n",
    "    with open(test_dir + test_name, 'r') as f:\n",
    "        for line in f.readlines()[1:]:\n",
    "            line_tokens = line.split()\n",
    "            query_name_tokens = line_tokens[0].split('.')[0].split('_')\n",
    "            query_size = int(query_name_tokens[2])\n",
    "            query_type = query_name_tokens[1]\n",
    "            if pure:\n",
    "                pred = math.log10(max(1.0, float(line_tokens[2])))\n",
    "                card = math.log10(float(line_tokens[3]))\n",
    "            else:\n",
    "                pred = float(line_tokens[2]) * math.log10(2)\n",
    "                card = float(line_tokens[3]) * math.log10(2)\n",
    "            q_error = pred - card\n",
    "            res.append([file_name, epochs, query_size, query_type, pred, card, q_error])\n",
    "    return res\n",
    "\n",
    "def read_train_file(file_name, train_dir, train_name, pure=False):\n",
    "    # train_data = [['File Name', 'Epochs', 'Loss'], [...], ...]\n",
    "    res = []\n",
    "    with open(train_dir + train_name, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if line.startswith('Epoch '):\n",
    "                tokens = line.split(' ')\n",
    "                epoch = int(tokens[1].split('/')[0])\n",
    "                loss = float(tokens[-1])\n",
    "                res.append([file_name, epoch, loss])\n",
    "    return res\n",
    "\n",
    "def read_parameters_file(file_name, params_dir, params_name):\n",
    "    # params_data = [['File Name', 'Learning Rate', 'Epochs'], [...], ...]\n",
    "    res = []\n",
    "    with open(params_dir + params_name) as f:\n",
    "        for line in f.readlines():\n",
    "            if line.startswith('learning rate'):\n",
    "                lr = float(line.split(':')[1].strip())\n",
    "            if line.startswith('epochs'):\n",
    "                epoch = int(line.split(':')[1].strip())\n",
    "    res.append([file_name, lr, epoch])\n",
    "    return res\n",
    "\n",
    "def draw_box_plot(dataframe, title, fontsize=12):\n",
    "    bp = sns.boxplot(data=dataframe, x='Query Size', y='q-error', whis=[1, 99], hue='File Name')\n",
    "    plt.title(title, fontsize=fontsize)\n",
    "    plt.grid(True)\n",
    "    plt.axhline(0, color='green',linestyle='dashed')\n",
    "    plt.ylabel('Under estimate <--- log10(q-error) ---> Over estimate', fontsize=fontsize)\n",
    "    plt.xlabel('Query Size', fontsize=fontsize)\n",
    "    # plt.yticks(ticks=[-6, -4, -2, 0, 2, 4, 6], labels=['$10^6$', '$10^4$', '$10^2$', '$10^0$', '$10^2$', '$10^4$', '$10^6$'])\n",
    "    # pcntls = df.groupby('Query Size')['q-error'].describe(percentiles=[0.1, 0.9])\n",
    "    # pcntls = pcntls.sort_values(by='Query Size')\n",
    "    # columns = len(pcntls['10%'])\n",
    "    # bp.scatter(data=pcntls, x=range(columns), y='10%', marker='x')\n",
    "    # bp.scatter(data=pcntls, x=range(columns), y='90%', marker='x')\n",
    "    plt.show()\n",
    "\n",
    "def draw_line_plot(df, title, fontsize=12):\n",
    "    bp = sns.lineplot(data=df, x='Epochs', y='Loss', hue='File Name')\n",
    "    plt.xlabel('Epochs', fontsize=fontsize)\n",
    "    plt.ylabel('Loss', fontsize=fontsize)\n",
    "    plt.title(title, fontsize=fontsize)\n",
    "    plt.ylim((0, 3000))\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data_graph = 'yeast'\n",
    "    test_dir = 'saved_results/'\n",
    "    params_dir = 'saved_params/'\n",
    "    train_dir = 'outputs/{}/'.format(data_graph)\n",
    "    file_names = [\n",
    "        '100_baseline_0',\n",
    "        '100_baseline_1',\n",
    "        '100_baseline_2',\n",
    "        '100_baseline_3',\n",
    "        '100_baseline_4',\n",
    "        # 'better_performance_mse_log2_0', \n",
    "        # 'better_performance_mse_log2_scheduler_0',\n",
    "        # '2_lr_0.001',\n",
    "        # '2_lr_0.0001',\n",
    "        # '2_lr_0.0003',\n",
    "        # '2_lr_0.005',\n",
    "        # '2_lr_0.0005',\n",
    "        # '2_lr_0.0008',\n",
    "        # 'dropout_lr_0.001',\n",
    "        # 'dropout_lr_0.0003',\n",
    "        # 'dropout_lr_0.0001',\n",
    "        # 'dropout_lr_0.005',\n",
    "        # 'dropout_lr_0.0005',\n",
    "        # 'dropout_lr_0.0008',\n",
    "        # -'dropout_leaky_relu_lr_0.001',\n",
    "        # 'dropout_leaky_relu_lr_0.0001',\n",
    "        # 'dropout_leaky_relu_lr_0.0003',\n",
    "        # 'dropout_leaky_relu_lr_0.005',\n",
    "        # 'dropout_leaky_relu_lr_0.0005',\n",
    "        # 'dropout_leaky_relu_lr_0.0008',\n",
    "        # 'dropout_scheduler_lr_0.001',\n",
    "        # 'dropout_scheduler_lr_0.0001',\n",
    "        # 'dropout_scheduler_lr_0.0003',\n",
    "        # 'dropout_scheduler_lr_0.005',\n",
    "        # 'dropout_scheduler_lr_0.0005',\n",
    "        # 'dropout_scheduler_lr_0.0008',\n",
    "        ]\n",
    "\n",
    "    test_data = []\n",
    "    train_data = []\n",
    "    params_data = []\n",
    "    pures = [True for _ in file_names]\n",
    "    for idx, file_name in enumerate(file_names):\n",
    "        test_params_name = list(filter(lambda x: file_name in x, os.listdir(test_dir)))\n",
    "        if len(test_params_name) != 1:\n",
    "            raise Exception(test_params_name)\n",
    "        train_name = list(filter(lambda x: file_name in x, os.listdir(train_dir)))\n",
    "        if len(train_name) != 1:\n",
    "            raise Exception(train_name)\n",
    "        test_data.extend(read_test_file(file_name, test_dir, test_params_name[0], pures[idx]))\n",
    "        params_data.extend(read_parameters_file(file_name, params_dir, test_params_name[0]))\n",
    "        train_data.extend(read_train_file(file_name, train_dir, train_name[0], pures[idx]))\n",
    "\n",
    "    test_data = pd.DataFrame(data=test_data, columns=['File Name', 'Epochs', 'Query Size', 'Query Type', 'Pred', 'Card', 'q-error'])\n",
    "    test_data = test_data.sort_values(by='Query Size')\n",
    "    train_data = pd.DataFrame(data=train_data, columns=['File Name', 'Epochs', 'Loss'])\n",
    "    params_data = pd.DataFrame(data=params_data, columns=['File Name', 'Learning Rate', 'Epochs'])\n",
    "    interperting_results(file_names, test_data.copy(), params_data.copy())\n",
    "    draw_box_plot(test_data, data_graph)\n",
    "    draw_line_plot(train_data, data_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "exist = os.listdir('./saved_results/')\n",
    "\n",
    "for file in os.listdir('./saved_params/'):\n",
    "    if file not in exist:\n",
    "        os.remove('./saved_params/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
